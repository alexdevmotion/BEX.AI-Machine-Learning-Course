{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEX.AI 02 Lab Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmUpExercise():\n",
    "    \"\"\"\n",
    "    Return the 5x5 identity matrix.\n",
    "    \"\"\"    \n",
    "    # ======== YOUR CODE HERE ======\n",
    "    A = []\n",
    "    # ==============================\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "       [ 0.,  1.,  0.,  0.,  0.],\n",
    "       [ 0.,  0.,  1.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.,  1.,  0.],\n",
    "       [ 0.,  0.,  0.,  0.,  1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmUpExercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read comma separated data\n",
    "data = np.loadtxt('ex1data1.txt', delimiter=',')\n",
    "X, y = data[:, 0], data[:, 1]\n",
    "\n",
    "m = y.size  # number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x, y):\n",
    "    \"\"\"\n",
    "    Plots the data points x and y into a new figure. Plots the data \n",
    "    points and gives the figure axes labels of population and profit.\n",
    "    \"\"\"\n",
    "    fig = pyplot.figure()  # open a new figure\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================= \n",
    "    pyplot.plot(x, y, 'bo', ms=5, mec='k')\n",
    "    pyplot.ylabel('Profit in $10,000')\n",
    "    pyplot.xlabel('Population of City in 10,000s')\n",
    "    # ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pyplot.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will fit the linear regression parameters $\\theta$ to our dataset using gradient descent.\n",
    "\n",
    "#### Update Equations\n",
    "\n",
    "The objective of linear regression is to minimize the cost function\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left( h_{\\theta}(x^{(i)}) - y^{(i)}\\right)^2$$\n",
    "\n",
    "where the hypothesis $h_\\theta(x)$ is given by the linear model\n",
    "$$ h_\\theta(x) = \\theta^Tx = \\theta_0 + \\theta_1 x_1$$\n",
    "\n",
    "Recall that the parameters of your model are the $\\theta_j$ values. These are\n",
    "the values you will adjust to minimize cost $J(\\theta)$. One way to do this is to\n",
    "use the batch gradient descent algorithm. In batch gradient descent, each\n",
    "iteration performs the update\n",
    "\n",
    "$$ \\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{simultaneously update } \\theta_j \\text{ for all } j$$\n",
    "\n",
    "With each step of gradient descent, your parameters $\\theta_j$ come closer to the optimal values that will achieve the lowest cost J($\\theta$).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Implementation Note:** We store each example as a row in the the $X$ matrix in Python `numpy`. To take into account the intercept term ($\\theta_0$), we add an additional first column to $X$ and set it to all ones. This allows us to treat $\\theta_0$ as simply another 'feature'.\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "We have already set up the data for linear regression. In the following cell, we add another dimension to our data to accommodate the $\\theta_0$ intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to X. The numpy function stack joins arrays along a given axis. \n",
    "# The first axis (axis=0) refers to rows (training examples) \n",
    "# and second axis (axis=1) refers to columns (features).\n",
    "X2 = np.stack([np.ones(m), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression. Computes the cost of using theta as the\n",
    "    parameter for linear regression to fit the data points in X and y.\n",
    "    HINTS: np.dot, np.sum\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    J = 0\n",
    "    \n",
    "    # ====================== YOUR CODE HERE =====================\n",
    "    h = np.dot(X, theta)\n",
    "    J = 1/(2*m)*np.sum(np.square(h-y))\n",
    "    # ===========================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With theta = [0, 0] \n",
      "Cost computed = 32.07\n",
      "Expected cost value (approximately) 32.07\n",
      "\n",
      "With theta = [-1, 2]\n",
      "Cost computed = 54.24\n",
      "Expected cost value (approximately) 54.24\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(X2, y, theta=np.array([0.0, 0.0]))\n",
    "print('With theta = [0, 0] \\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 32.07\\n')\n",
    "\n",
    "# further testing of the cost function\n",
    "J = computeCost(X2, y, theta=np.array([-1, 2]))\n",
    "print('With theta = [-1, 2]\\nCost computed = %.2f' % J)\n",
    "print('Expected cost value (approximately) 54.24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Gradient descent\n",
    "\n",
    "Next, you will complete a function which implements gradient descent.\n",
    "The loop structure has been written for you, and you only need to supply the updates to $\\theta$ within each iteration. \n",
    "\n",
    "A good way to verify that gradient descent is working correctly is to look at the value of $J(\\theta)$ and check that it is decreasing with each step. \n",
    "\n",
    "The starter code for the function `gradientDescent` calls `computeCost` on every iteration and saves the cost to a `python` list. Assuming you have implemented gradient descent and `computeCost` correctly, your value of $J(\\theta)$ should never increase, and should converge to a steady value by the end of the algorithm.\n",
    "\n",
    "<div class=\"alert alert-box alert-warning\">\n",
    "**Vectors and matrices in `numpy`** - Important implementation notes\n",
    "\n",
    "A vector in `numpy` is a one dimensional array, for example `np.array([1, 2, 3])` is a vector. A matrix in `numpy` is a two dimensional array, for example `np.array([[1, 2, 3], [4, 5, 6]])`. However, the following is still considered a matrix `np.array([[1, 2, 3]])` since it has two dimensions, even if it has a shape of 1x3 (which looks like a vector).\n",
    "\n",
    "Given the above, the function `np.dot` which we will use for all matrix/vector multiplication has the following properties:\n",
    "- It always performs inner products on vectors. If `x=np.array([1, 2, 3])`, then `np.dot(x, x)` is a scalar.\n",
    "- For matrix-vector multiplication, so if $X$ is a $m\\times n$ matrix and $y$ is a vector of length $m$, then the operation `np.dot(y, X)` considers $y$ as a $1 \\times m$ vector. On the other hand, if $y$ is a vector of length $n$, then the operation `np.dot(X, y)` considers $y$ as a $n \\times 1$ vector.\n",
    "- A vector can be promoted to a matrix using `y[None]` or `[y[np.newaxis]`. That is, if `y = np.array([1, 2, 3])` is a vector of size 3, then `y[None, :]` is a matrix of shape $1 \\times 3$. We can use `y[:, None]` to obtain a shape of $3 \\times 1$.\n",
    "<div>\n",
    "<a id=\"gradientDescent\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn `theta`. Updates theta by taking `num_iters`\n",
    "    gradient steps with learning rate `alpha`.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0]  # number of training examples\n",
    "    \n",
    "    # make a copy of theta, to avoid changing the original array, since numpy arrays\n",
    "    # are passed by reference to functions\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = [] # Use a python list to save cost in every iteration\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ==================== YOUR CODE HERE =================================\n",
    "        h = np.dot(X, theta)\n",
    "        theta = theta - alpha*(1/m)*np.dot(X.T, h-y)\n",
    "        # =====================================================================\n",
    "        \n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(computeCost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (97,) and (2,) not aligned: 97 (dim 0) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-426a1f441309>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Theta found by gradient descent: {:.4f}, {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected theta values (approximately): [-3.6303, 1.1664]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-dee7b382743e>\u001b[0m in \u001b[0;36mgradientDescent\u001b[1;34m(X, y, theta, alpha, num_iters)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# ==================== YOUR CODE HERE =================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# =====================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (97,) and (2,) not aligned: 97 (dim 0) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "# initialize fitting parameters\n",
    "theta = np.zeros(2)\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "theta, J_history = gradientDescent(X ,y, theta, alpha, iterations)\n",
    "print('Theta found by gradient descent: {:.4f}, {:.4f}'.format(*theta))\n",
    "print('Expected theta values (approximately): [-3.6303, 1.1664]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bexai",
   "language": "python",
   "name": "bexai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
